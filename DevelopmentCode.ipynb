{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import uptide\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('data/aberdeen/2000ABE.txt', header=9, delim_whitespace=True)\n",
    "# read in fixed-width file, skipping the header\n",
    "df1 = pd.read_fwf('data/1947ABE.txt', skiprows=9)\n",
    "\n",
    "# remove units row\n",
    "df1.drop(0, inplace=True)\n",
    "\n",
    "# rename sea level column\n",
    "df1.rename(columns={df1.columns[3]: 'Sea Level'}, inplace=True)\n",
    "\n",
    "# drop cycle column\n",
    "df1.drop(columns=df1.columns[0], inplace=True)\n",
    "\n",
    "# remove dodgy values\n",
    "df1.replace(to_replace=\".*T$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "df1.replace(to_replace=\".*N$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "df1.replace(to_replace=\".*M$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "df1.replace(to_replace=\".*T$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "df1.replace(to_replace=\".*N$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "df1.replace(to_replace=\".*M$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "\n",
    "# convert strings to numbers and datetimes\n",
    "df1['Date'] = pd.to_datetime(df1['Date'], format='%Y/%m/%d')\n",
    "df1['Time'] = pd.to_datetime(df1['Time'], format='%H:%M:%S') # or pd.to_timedelta(df1['Time'], unit='s')\n",
    "df1['Sea Level'] = df1['Sea Level'].astype('float')\n",
    "df1['Residual'] = df1['Residual'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1['datetime'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tidal_data(filename):\n",
    "   # Reads in filename into a pandas dataframe which is cleaned and formatted. Returns the dataframe.\n",
    "   \n",
    "   # read in fixed-width file, skipping the header\n",
    "   df = pd.read_fwf(filename, skiprows=9)\n",
    "\n",
    "   # remove units row\n",
    "   df.drop(0, inplace=True)\n",
    "\n",
    "   # rename sea level column\n",
    "   df.rename(columns={df.columns[3]: 'Sea Level'}, inplace=True)\n",
    "\n",
    "   # drop cycle column\n",
    "   df.drop(columns=df.columns[0], inplace=True)\n",
    "\n",
    "   # remove dodgy values\n",
    "   df.replace(to_replace=\".*T$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "   df.replace(to_replace=\".*N$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "   df.replace(to_replace=\".*M$\",value={'Sea Level':np.nan},regex=True,inplace=True)\n",
    "   df.replace(to_replace=\".*T$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "   df.replace(to_replace=\".*N$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "   df.replace(to_replace=\".*M$\",value={'Residual':np.nan},regex=True,inplace=True)\n",
    "\n",
    "   # convert strings to numbers and datetimes\n",
    "   df['Date'] = pd.to_datetime(df['Date'], format='%Y/%m/%d')\n",
    "   df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S') # or pd.to_timedelta(df['Time'], unit='s')\n",
    "   df['Sea Level'] = df['Sea Level'].astype('float')\n",
    "   df['Residual'] = df['Residual'].astype('float')\n",
    "\n",
    "   # create datetime column\n",
    "   df['datetime'] = df['Date'] + pd.to_timedelta(df['Time'].dt.time.astype(str))\n",
    "\n",
    "   # set datetime as index\n",
    "   df.set_index('datetime', inplace=True)\n",
    "\n",
    "   # NB don't drop Date and Time columns as they are used in tests\n",
    "\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_tidal_data(\"data/1947ABE.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"Sea Level\" in data.columns\n",
    "assert type(data.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "assert data['Sea Level'].size == 8760\n",
    "assert '1947-01-01 00:00:00' in data.index\n",
    "assert '1947-12-31 23:00:00' in data.index\n",
    "\n",
    "# check for M, N and T data; should be NaN\n",
    "assert data['Sea Level'].isnull().any()\n",
    "assert pd.api.types.is_float_dtype(data['Sea Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe next step is to use uptide module to work out tidal constuents but first have to remove np.nan values. Code that illustrates how to use the uptide module is found in the website: https://jhill1.github.io/SEPwC.github.io/tides_python.html so just have to follow that.\n",
    "\n",
    "Not sure if I need to refactor join_data so that it can handle more than two files - actually no because the skeleton function has arguments data1 and data2 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(data1, data2):\n",
    "   # Joins data1 and data2 vertically and returns the resulting dataframe\n",
    "   \n",
    "   # concatenate the data\n",
    "   combined_data = pd.concat([data1, data2])\n",
    "   # sort the index by ascending datetime\n",
    "   combined_data.sort_index(inplace=True)\n",
    "\n",
    "   return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_files = ['data/1946ABE.txt', 'data/1947ABE.txt']\n",
    "\n",
    "data1 = read_tidal_data(gauge_files[1])\n",
    "data2 = read_tidal_data(gauge_files[0])\n",
    "data = join_data(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_files = ['data/1946ABE.txt', 'data/1947ABE.txt']\n",
    "\n",
    "data1 = read_tidal_data(gauge_files[1])\n",
    "data2 = read_tidal_data(gauge_files[0])\n",
    "data = join_data(data1, data2)\n",
    "\n",
    "assert \"Sea Level\" in data.columns\n",
    "assert type(data.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "assert data['Sea Level'].size == 8760*2\n",
    "\n",
    "# check sorting (we join 1947 to 1946, but expect 1946 to 1947)\n",
    "assert data.index[0] == pd.Timestamp('1946-01-01 00:00:00')\n",
    "assert data.index[-1] == pd.Timestamp('1947-12-31 23:00:00')\n",
    "\n",
    "# check you get a fail if two incompatible dfs are given\n",
    "data2.drop(columns=[\"Sea Level\",\"Time\"], inplace=True)\n",
    "data = join_data(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_year_remove_mean(year, data):\n",
    "   # Takes in dataframe data containing multiple years of data and returns a dataframe containing only data from the year year. \n",
    "   # Also removes the mean by normalising the data.\n",
    "\n",
    "   if int(year) in data.index.year:\n",
    "      data = data[data.index.year == int(year)] # ensure year is an int and not a string\n",
    "   else:\n",
    "      print(\"The data does not contain the given year!\")\n",
    "      return -1\n",
    "\n",
    "   # Normalise sea level to remove the mean as in mini course\n",
    "   data['Sea Level'] = data['Sea Level'] - data['Sea Level'].mean()\n",
    "    \n",
    "   return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not sure if I have to normalise Residual too?? As idk if this will affect the coefficient calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_files = ['data/1946ABE.txt', 'data/1947ABE.txt']\n",
    "\n",
    "data1 = read_tidal_data(gauge_files[1])\n",
    "data2 = read_tidal_data(gauge_files[0])\n",
    "data = join_data(data1, data2)\n",
    "\n",
    "year1947 = extract_single_year_remove_mean(\"1947\",data)\n",
    "assert \"Sea Level\" in year1947.columns\n",
    "assert type(year1947.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "assert year1947['Sea Level'].size == 8760\n",
    "\n",
    "mean = np.mean(year1947['Sea Level'])\n",
    "print(mean)\n",
    "# check mean is near zero\n",
    "assert mean == pytest.approx(0)\n",
    "\n",
    "# check something sensible when a year is given that doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section_remove_mean(start, end, data):\n",
    "    # Takes in dataframe data and returns all rows between start date and end date inclusive.\n",
    "    # Also removes the mean by normalising the data.\n",
    "\n",
    "    # Ensure the index is a DatetimeIndex\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        data = data.copy()\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "    \n",
    "    # Convert arguments to datetimes\n",
    "    start = pd.to_datetime(start).date()\n",
    "    end = pd.to_datetime(end).date()\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    data = data[(data.index.date >= start) & (data.index.date <= end)]\n",
    "\n",
    "    # Normalise sea level to remove the mean as in mini course\n",
    "    data['Sea Level'] = data['Sea Level'] - data['Sea Level'].mean()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_files = ['data/1946ABE.txt', 'data/1947ABE.txt']\n",
    "\n",
    "data1 = read_tidal_data(gauge_files[1])\n",
    "data2 = read_tidal_data(gauge_files[0])\n",
    "data = join_data(data1, data2)\n",
    "\n",
    "year1946_47 = extract_section_remove_mean(\"19461215\", \"19470310\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year1946_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"Sea Level\" in year1946_47.columns\n",
    "assert type(year1946_47.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "assert year1946_47['Sea Level'].size == 2064\n",
    "\n",
    "mean = np.mean(year1946_47['Sea Level'])\n",
    "# check mean is near zero\n",
    "assert mean == pytest.approx(0)\n",
    "\n",
    "data_segment = extract_section_remove_mean(\"19470115\", \"19470310\", data1)\n",
    "assert \"Sea Level\" in data_segment.columns\n",
    "assert type(data_segment.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "assert data_segment['Sea Level'].size == 1320\n",
    "\n",
    "mean = np.mean(data_segment['Sea Level'])\n",
    "# check mean is near zero\n",
    "assert mean == pytest.approx(0)\n",
    "\n",
    "# check something sensible is done when dates are formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidal_analysis(data, constituents, start_datetime):\n",
    "   # Returns amplitude and phase for given constituents and sea level data using uptide library\n",
    "\n",
    "   # Need to remove NaNs before calculating tidal constituents\n",
    "   data = data[~data['Sea Level'].isna()]\n",
    "\n",
    "   # we create a Tides object with a list of the consituents we want.\n",
    "   tide = uptide.Tides(constituents)\n",
    "\n",
    "   # We then set out start time. All data must then be in second since this time\n",
    "   tide.set_initial_time(start_datetime)\n",
    "\n",
    "   # calculate seconds since start_datetime\n",
    "   seconds_since = (data.index.astype('int64').to_numpy()/1e9) - start_datetime.timestamp()\n",
    "\n",
    "   # Calculate amplitude and phase\n",
    "   amp, pha = uptide.harmonic_analysis(tide, data['Sea Level'].to_numpy(), seconds_since)\n",
    "   \n",
    "   return amp, pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_segment =extract_section_remove_mean(\"19460115\", \"19470310\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_segment.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_segment = data_segment[~data_segment['Sea Level'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_segment.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_files = ['data/1946ABE.txt', 'data/1947ABE.txt']\n",
    "data1 = read_tidal_data(gauge_files[1])\n",
    "data2 = read_tidal_data(gauge_files[0])\n",
    "data = join_data(data1, data2)\n",
    "\n",
    "data_segment =extract_section_remove_mean(\"19460115\", \"19470310\", data)\n",
    "\n",
    "constituents  = ['M2', 'S2']\n",
    "tz = pytz.timezone(\"utc\")\n",
    "start_datetime = datetime.datetime(1946,1,15,0,0,0, tzinfo=tz)\n",
    "amp,pha = tidal_analysis(data_segment, constituents, start_datetime)\n",
    "print(amp, pha)\n",
    "# for Aberdeen, the M2 and S2 amps are 1.307 and 0.441\n",
    "assert amp[0] == pytest.approx(1.307,abs=0.1)\n",
    "assert amp[1] == pytest.approx(0.441,abs=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD = pd.read_csv('h333.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
